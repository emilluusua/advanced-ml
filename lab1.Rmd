---
title: "Lab 1"
author: "Emil Luusua"
date: "17 September 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library(gRain)
library(caret)
data('asia')
```


## Question 1

Two runs of the hill-climbing algorithm can return non-equivalent BN structures. This can easily be shown by modifying the iss score parameter, which controls the imaginary sample size of the BDeu score.

```{r}
dag <- hc(asia, score = 'bde', iss = 1)
plot(dag)
plot(hc(asia, score = 'bde', iss = 2))
```

Note the additional arc between from 'A' to 'T' in the second plot. Differences in the resulting graph such as this can occur when using different scorings since it will influence how different aspects are weighted, in the case of iss the weight given to the prior is altered.

## Question 2

We start by splitting the data into train and test sets. Also extract labels S from the test set.
```{r}
set.seed(1)
sample_size <- floor(0.8 * nrow(asia))
train_indices <- sample(seq_len(nrow(asia)), size = sample_size)

asia_train <- asia[train_indices, ]
asia_test <- asia[-train_indices, ]
labels <- asia_test['S']
asia_test$S <- NULL
```

We use the structure learnt with by Hill Climbing in question 1 and learn the parameters of the model with Maximum Likelihood parameter estimation since we are not missing any data.
```{r}
fit <- bn.fit(dag, asia_train)
```

We perform classification of the test set using exact inference in gRain and display the results in a confusion matrix using caret.
```{r}
net <- compile(as.grain(fit))
data <- list()

for (i in seq_len(nrow(asia_test))) {
  evidence <- list()
  
  for (col in colnames(asia_test)) {
    evidence <- append(evidence, as.character(asia_test[i, col]))
  }
  
  posterior <- querygrain(setFinding(net, nodes=colnames(asia_test), states=evidence))$S
  
  if (posterior['yes'] > posterior['no']) {
    # Classify as positive
    data <- append(data, 'yes')
    
  } else {
    # Classify as negative
    data <- append(data, 'no')
  }
}
confusionMatrix(factor(unlist(data)), factor(unlist(labels)))
```

We then compare the results when using the true structure, with parameters still learned from the training data. This is shown to be exactly the same.
```{r}
true_dag <- model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]")
true_fit <- bn.fit(true_dag, asia_train)

true_net <- compile(as.grain(true_fit))
data <- list()

for (i in seq_len(nrow(asia_test))) {
  evidence <- list()
  
  for (col in colnames(asia_test)) {
    evidence <- append(evidence, as.character(asia_test[i, col]))
  }
  
  posterior <- querygrain(setFinding(true_net, nodes=colnames(asia_test), states=evidence))$S
  
  if (posterior['yes'] > posterior['no']) {
    # Classify as positive
    data <- append(data, 'yes')
    
  } else {
    # Classify as negative
    data <- append(data, 'no')
  }
}
confusionMatrix(factor(unlist(data)), factor(unlist(labels)))
```

## Question 3

What is the Markov blanket of S?
```{r}
mb(dag, 'S')
```

We thus perform the same procedure for classification as previously, only the evidence is altered such that it contains observations for L and B. Once again the results are identical.

```{r}
observations <- c('L', 'B')
data <- list()

for (i in seq_len(nrow(asia_test))) {
  evidence <- list()
  
  for (col in observations) {
    evidence <- append(evidence, as.character(asia_test[i, col]))
  }
  
  posterior <- querygrain(setFinding(net, nodes=observations, states=evidence))$S
  
  if (posterior['yes'] > posterior['no']) {
    # Classify as positive
    data <- append(data, 'yes')
    
  } else {
    # Classify as negative
    data <- append(data, 'no')
  }
}
confusionMatrix(factor(unlist(data)), factor(unlist(labels)))
```

A Naïve Bayes classifier can be represented by a Bayesian network where the prediction variable is the sole parent of all other variables. This will result in the graph representing the same conditional independence as is assumed for a Naïve Bayes model.
```{r}
naive_dag <- model2network("[S][A|S][T|S][L|S][B|S][D|S][E|S][X|S]")
naive_fit <- bn.fit(naive_dag, asia_train)
plot(naive_dag)
```

Now once again we perform classification of S by observing all other variables, and once again the same results are achieved.
```{r}
naive_net <- compile(as.grain(fit))
data <- list()

for (i in seq_len(nrow(asia_test))) {
  evidence <- list()
  
  for (col in colnames(asia_test)) {
    evidence <- append(evidence, as.character(asia_test[i, col]))
  }
  
  posterior <- querygrain(setFinding(naive_net, nodes=colnames(asia_test), states=evidence))$S
  
  if (posterior['yes'] > posterior['no']) {
    # Classify as positive
    data <- append(data, 'yes')
    
  } else {
    # Classify as negative
    data <- append(data, 'no')
  }
}
confusionMatrix(factor(unlist(data)), factor(unlist(labels)))
```

## Question 5
So throughout all experiments, the same results have been achieved using four different models of the data. How can this possibly make sense?

The first three cases are quite clear, since S will have the same Markov blanket in all these graphs (L and B). As these variables are observed in each case, the S node will be independent from all other nodes. As such observing the other nodes or modeling the independencies among them will not make a difference to the classification of S.

The Naïve Bayes network is quite different though, and could very well yield a different result since ALL variables will be taken into account when performing the classification in comparison to only L and B in earlier cases. The result could be better since even if the other nodes are deemed independent in the Bayes Networks, there might be a small correlation with S that could still benefit classification but was not considered worthy of the added model complexity. Or it could make the results worse by introducing false dependencies making the predictions "noisier" because of the relatively small dataset. In this case though, it seems that L and B dominate the decision made by the Naive Bayes model as well resulting in the exact same predictions.